{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "---\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "This notebook shows and documents the implementation of a Traffic Sign Recognition Classifier loosely based on the LeNet convolutional neural network architecture.\n",
    "\n",
    "The input images come from the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset). An analysis of the dataset is shown and an augmentation strategy for it proposed and implemented.\n",
    "\n",
    "The classifier is trained using an AWS GPU instance, and reaches an accuracy of more than 93%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## General Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Data import/management/handling\n",
    "import pickle\n",
    "import csv\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Plotting and image manipulation\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "# Time is used to measure performances in training\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading and Analyzing the Data\n",
    "\n",
    "The original pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original pickled data\n",
    "training_file = '../traffic-signs-data/train.p'\n",
    "validation_file='../traffic-signs-data/valid.p'\n",
    "testing_file = '../traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Summary of the Data Set\n",
    "\n",
    "We can assess/verify:\n",
    "\n",
    "* The size of the Training/Validation/Test dataset\n",
    "* The shape (size) of the images\n",
    "* The number of idipendent classes (type of traffic signes) to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training examples: the length of X_train\n",
    "n_train = len(X_train)\n",
    "\n",
    "# Number of validation examples: the length of X_valid\n",
    "n_validation = len(X_valid)\n",
    "\n",
    "# Number of validation examples: the length of X_test\n",
    "n_test = len(X_test)\n",
    "\n",
    "# Shape of the image: any element of X_train/X_valid/X_test can be used to deduce it\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# To identify the number of classes in the dataset we can extract the number of unique elements in the label vectors\n",
    "u_classes, indices_uc = np.unique(y_train, return_index=True)\n",
    "n_classes = len(u_classes)\n",
    "\n",
    "# Finally, it is also a good idea to verify that the dataset is consistent\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_valid) == len(y_valid))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "# Printout results\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and Analysis\n",
    "\n",
    "The next two cells of code are going to: \n",
    "* Provide a visualization of the first instance of every class in the training datatset\n",
    "* Calculate the actual number of occurrences for every class in the training dataset and then visualize them as an histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an instance of every image\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the output image for 7 columns, and derive the number of rows\n",
    "n_columns = 7\n",
    "n_rows = int(np.ceil(len(u_classes)/n_columns))\n",
    "\n",
    "# Define a reference size for the output figure\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Iterate over the vector of indices obtained in the previous code cell \n",
    "i=0\n",
    "for index in (indices_uc):\n",
    "    image = X_train[index]\n",
    "    i=i+1\n",
    "    plt.subplot(n_rows,n_columns,i)    \n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a histogram of the training data\n",
    "\n",
    "# First, identify the number of occurrence for each label: we can use a counter on the y_train vector for this\n",
    "#\n",
    "z = np.array(Counter(y_train).most_common())\n",
    "lbls=z[:,0] # Array of lables\n",
    "occs=z[:,1] # Occurrence of every label, ordered from the most common\n",
    "\n",
    "# To make the histogram more meaningful, we're going to plot the occurrence against the actual text describing\n",
    "# the sign, rather than the alphanumeric label. To couple the two, we need to parse the 'signames.csv' file\n",
    "#\n",
    "lbls_text=[] # Vector that will contain the parsed output of the .csv\n",
    "lbls_sh=[]   # Vector that will contain the \"shuffled\" labels, ordered from the most common \n",
    "\n",
    "with open('signnames.csv', newline='') as csvfile:\n",
    "    filereader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in filereader:\n",
    "        if row[0].isnumeric():\n",
    "            lbls_text.append(row[1])\n",
    "\n",
    "for i in np.nditer(lbls):\n",
    "    lbls_sh.append(lbls_text[i])\n",
    "\n",
    "# Finally we can plot the histogram\n",
    "#\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.barh(lbls,occs,align='center', alpha=0.5)\n",
    "plt.yticks(lbls, lbls_sh)\n",
    "plt.xlabel('Occurrences')\n",
    "plt.title('Occurrence of labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Augmentation of the Original Dataset\n",
    "\n",
    "The original dataset seems to be heavily unbalanced, with some signs significantly more common than others. Another characteristics that seems to describe the original data is the degree of \"darkness\" of some images.\n",
    "\n",
    "In order to cope with bothe the issues we are going to use an _augmented_ the dataset containing additional images. Those images would be:\n",
    "\n",
    "* Generated by the original ones, applying a random rotation and/or a random change in lighthing \n",
    "* In a number such that every class will have a number of instances exactly equal to the one that currently is the most represented ('Speed Limit (50 km/h)', with 2010 occurrences)\n",
    "\n",
    "> **Note**: The set of code cells performing the augmentation is actually _very_ time consuming to run. For this reason, thay are included as an appendix at the bottom of this notebook, but in the following the extended data is directly loaded from a dictionary with only the `'augmented_features'` and `'augmented_labels'` pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading augmented training dataset\n",
    "extended_training_file = '../traffic-signs-data/augmented_train.p'\n",
    "\n",
    "with open(extended_training_file, mode='rb') as f:\n",
    "    aug_train = pickle.load(f)\n",
    "    \n",
    "X_train_aug,y_train_aug = aug_train['augmented_pictures'], aug_train['augmented_labels']\n",
    "\n",
    "\n",
    "# Number of training examples: the length of X_train_aug\n",
    "n_train_aug = len(X_train_aug)\n",
    "\n",
    "# Consistency check\n",
    "assert(len(X_train_aug) == len(y_train_aug))\n",
    "\n",
    "# Printout results\n",
    "print(\"Number of augmented training examples =\", n_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an instance of every image in the augmented dataset\n",
    "\n",
    "# Note: in case needed, the following values can change - otherwise thay can be left as they were for plotting the \n",
    "# original dataset\n",
    "# n_columns = 7\n",
    "# n_rows = int(np.ceil(len(u_classes)/n_columns))\n",
    "\n",
    "# The augmentation routine appended the new images at the bottom of the original vectors, so we need a shuffle or \n",
    "# we'd see the same picture shown before\n",
    "X_train_aug, y_train_aug = shuffle(X_train_aug, y_train_aug)\n",
    "\n",
    "# Given the shuffle, we'll have to recalculate the indices for the first occurrence of every class\n",
    "u_classes, indices_uc = np.unique(y_train_aug, return_index=True)\n",
    "\n",
    "# Define a reference size for the output figure\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Iterate over the vector of indices obtained here\n",
    "i=0\n",
    "for index in (indices_uc):\n",
    "    image = X_train_aug[index]\n",
    "    i=i+1\n",
    "    plt.subplot(n_rows,n_columns,i)    \n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a histogram of the training data\n",
    "# The code in this cell is mostly the same that was used for the previous histogram, with the only \n",
    "# change in the vector we're using\n",
    "\n",
    "# First, identify the number of occurrence for each label: we can use a counter on the y_train_aug vector for this\n",
    "#\n",
    "z = np.array(Counter(y_train_aug).most_common())\n",
    "lbls=z[:,0] # Array of lables\n",
    "occs=z[:,1] # Occurrence of every label, ordered from the most common\n",
    "\n",
    "# To make the histogram more meaningful, we're going to plot the occurrence against the actual text describing\n",
    "# the sign, rather than the alphanumeric label. To couple the two, we already parsed the 'signames.csv' file\n",
    "#\n",
    "# lbls_text is a vector containing the parsed output of the .csv, and was obtained for the previous histogram\n",
    "#\n",
    "lbls_sh=[]   # Vector that will contain the \"shuffled\" labels, ordered from the most common \n",
    "\n",
    "for i in np.nditer(lbls):\n",
    "    lbls_sh.append(lbls_text[i])\n",
    "\n",
    "# Finally we can plot the histogram\n",
    "#\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.barh(lbls,occs,align='center', alpha=0.5)\n",
    "plt.yticks(lbls, lbls_sh)\n",
    "plt.xlabel('Occurrences')\n",
    "plt.title('Occurrence of labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Definition of the Neural Network Architecture\n",
    "\n",
    "As detailed in the readme file serving as a writeup for this project, the starting point for this Neural Network Architecture was LeNet, with some subsequent modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing of the images\n",
    "\n",
    "The actual pre-processing required on the images is fairly minimal, with simple normalization to fall in the range \\[-128,128\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing input data\n",
    "\n",
    "X_train_aug = (X_train_aug-128.0)/128\n",
    "X_valid = (X_valid-128.0)/128\n",
    "X_test = (X_test-128.0)/128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiton of Num. of Epochs/Batch size \n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyNet(x):    \n",
    "    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    # In the following the dimension of the Output of the convolutional layers will be calculated using the equations\n",
    "    # - for VALID PADDING:\n",
    "    #\n",
    "    # out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "    # out_width = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Layer 1: Convolutional. \n",
    "    # Input = 32x32x3. \n",
    "    # Filter size = 5x5, VALID padding, Strides = 1\n",
    "    # Output = 28x28x6\n",
    "    #\n",
    "    Weights_c1 = tf.Variable(tf.random_normal([5, 5, 3, 6], mean = mu, stddev = sigma))\n",
    "    Bias_c1 = tf.Variable(tf.random_normal([6], mean = mu, stddev = sigma))\n",
    "    c1 = tf.nn.conv2d(x, Weights_c1, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    c1 = tf.nn.bias_add(c1, Bias_c1)\n",
    "    \n",
    "    # Layer 1: Activation.\n",
    "    c1 = tf.nn.relu(c1,name='Layer1_0')\n",
    "    \n",
    "    \n",
    "    # Layer 2: Convolutional. \n",
    "    # Input = 28x28x6.\n",
    "    # Filter size = 5x5, VALID padding, Strides = 1\n",
    "    # Output = 24x24x12\n",
    "    #\n",
    "    Weights_c2 = tf.Variable(tf.random_normal([5, 5, 6, 12], mean = mu, stddev = sigma))\n",
    "    Bias_c2 = tf.Variable(tf.random_normal([12], mean = mu, stddev = sigma))\n",
    "    c2 = tf.nn.conv2d(c1, Weights_c2, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    c2 = tf.nn.bias_add(c2, Bias_c2)\n",
    "       \n",
    "    # Layer 2: Activation.\n",
    "    c2 = tf.nn.relu(c2,name='Layer2_0')\n",
    "    \n",
    "    # Layer 2: Droput \n",
    "    c2 = tf.nn.dropout(c2,0.50)\n",
    "    \n",
    "    \n",
    "    # Layer 3: Convolutional. \n",
    "    # Input = 24x24x12\n",
    "    # Filter size = 5x5, VALID padding, Strides = 1\n",
    "    # Output = 20x20x20\n",
    "    #\n",
    "    Weights_c3 = tf.Variable(tf.random_normal([5, 5, 12, 20], mean = mu, stddev = sigma))\n",
    "    Bias_c3 = tf.Variable(tf.random_normal([20], mean = mu, stddev = sigma))\n",
    "    c3 = tf.nn.conv2d(c2, Weights_c3, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    c3 = tf.nn.bias_add(c3, Bias_c3)\n",
    "    \n",
    "    # Layer 3: Activation.\n",
    "    c3 = tf.nn.relu(c3,name='Layer3_0')\n",
    "    \n",
    "    \n",
    "    # Layer 4: Convolutional. \n",
    "    # Input = 20x20x20\n",
    "    # Filter size = 5x5, VALID padding, Strides = 1\n",
    "    # Output = 16x16x30\n",
    "    #\n",
    "    Weights_c4 = tf.Variable(tf.random_normal([5, 5, 20, 30], mean = mu, stddev = sigma))\n",
    "    Bias_c4 = tf.Variable(tf.random_normal([30], mean = mu, stddev = sigma))\n",
    "    c4 = tf.nn.conv2d(c3, Weights_c4, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    c4 = tf.nn.bias_add(c4, Bias_c4)\n",
    "    \n",
    "    # Layer 4: Activation.\n",
    "    c4 = tf.nn.relu(c4,name='Layer4_0')\n",
    "    \n",
    "    # Layer 4: Dropout.\n",
    "    c4 = tf.nn.dropout(c4,0.50)\n",
    "    \n",
    "    \n",
    "    # Layer 5: Convolutional. \n",
    "    # Input = 16x16x30\n",
    "    # Filter size = 5x5, VALID padding, Strides = 1\n",
    "    # Output = 12x12x45\n",
    "    #\n",
    "    Weights_c5 = tf.Variable(tf.random_normal([5, 5, 30, 45], mean = mu, stddev = sigma))\n",
    "    Bias_c5 = tf.Variable(tf.random_normal([45], mean = mu, stddev = sigma))\n",
    "    c5 = tf.nn.conv2d(c4, Weights_c5, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    c5 = tf.nn.bias_add(c5, Bias_c5)\n",
    "    \n",
    "    # Layer 5: Activation.\n",
    "    c5 = tf.nn.relu(c5,name='Layer5_0')\n",
    "   \n",
    "    \n",
    "    # Layer 6: Convolutional. \n",
    "    # Input = 12x12x45\n",
    "    # Filter size = 5x5, VALID padding, Strides = 1\n",
    "    # Output = 8x8x70\n",
    "    #\n",
    "    Weights_c6 = tf.Variable(tf.random_normal([5, 5, 45, 70], mean = mu, stddev = sigma))\n",
    "    Bias_c6 = tf.Variable(tf.random_normal([70], mean = mu, stddev = sigma))\n",
    "    c6 = tf.nn.conv2d(c5, Weights_c6, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    c6 = tf.nn.bias_add(c6, Bias_c6)\n",
    "    \n",
    "    # Layer 6: Activation.\n",
    "    c6 = tf.nn.relu(c6,name='Layer6_0')\n",
    "    \n",
    "    # Layer 6: Dropout.\n",
    "    c6 = tf.nn.dropout(c6,0.50)\n",
    "    \n",
    "    # Layer 6: Flattening.\n",
    "    c6 = flatten(c6)\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Layer 7: Fully Connected. Input = 8x8x70 = 4480. Output = 400.\n",
    "    #\n",
    "    Weights_c7 = tf.Variable(tf.random_normal([4480, 400], mean = mu, stddev = sigma))\n",
    "    Bias_c7 = tf.Variable(tf.random_normal([400], mean = mu, stddev = sigma))\n",
    "    c7 = tf.matmul(c6, Weights_c7) + Bias_c7\n",
    "    \n",
    "    # Layer 7: Activation.\n",
    "    c7 = tf.nn.relu(c7,name='Layer7')\n",
    "\n",
    "    # Layer 8: Fully Connected. Input = 400. Output = 100.\n",
    "    #\n",
    "    Weights_c8 = tf.Variable(tf.random_normal([400, 100], mean = mu, stddev = sigma))\n",
    "    Bias_c8 = tf.Variable(tf.random_normal([100], mean = mu, stddev = sigma))\n",
    "    c8 = tf.matmul(c7, Weights_c8) + Bias_c8\n",
    "    \n",
    "    # Layer 8: Activation.\n",
    "    c8 = tf.nn.relu(c8,name='Layer8')\n",
    "    \n",
    "    # Layer 8: Droput.\n",
    "    c8 = tf.nn.dropout(c8,0.50)\n",
    "\n",
    "    # Layer 9: Classifier, fully Connected. Input = 100. Output = 43.\n",
    "    Weights_c9 = tf.Variable(tf.random_normal([100, 43], mean = mu, stddev = sigma))\n",
    "    Bias_c9 = tf.Variable(tf.random_normal([43], mean = mu, stddev = sigma))\n",
    "    logits = tf.matmul(c8, Weights_c9) + Bias_c9\n",
    " \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Validate the Model\n",
    "\n",
    "The following are standard reference cells, with minimal modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TensorFlow placeholders for the training\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32,3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optmizations routines/parameter\n",
    "\n",
    "rate = 0.001 # Learning Rate: will be kept constant, using the Adam optimization algorythm\n",
    "\n",
    "logits = MyNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction/operation routines and evaluation functions\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a saver for the model\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, measuring the time needed \n",
    "\n",
    "t = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train_aug)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        X_train_aug, y_train_aug = shuffle(X_train_aug, y_train_aug)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_aug[offset:end], y_train_aug[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './mynet')\n",
    "    print(\"Model saved\")\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"Elapsed time (in seconds)\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model against the test data\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test the Model on New Images\n",
    "\n",
    "6 images of traffic signs have been downloaded from the internet and will be scanned using the model just trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images have already been pre-processed and saved in a \\[32x32x3\\] format. They will be scanned from 6 independent .jpg files, loaded in an array of the appropriate shape, and then shown.\n",
    "The labels defining them were identified from the `signnames.csv` file, and will be hard-coded in a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a reference size for the output image\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Iterate over images \n",
    "X_test_web=np.zeros((6,image_shape[0],image_shape[1],3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    in_image = mpimg.imread(\"traffic_sigs_test-examples/Signal_{}.jpg\".format(i))\n",
    "    X_test_web[i-1] = in_image\n",
    "    \n",
    "    plt.subplot(1,6,i)\n",
    "    plt.imshow(in_image)\n",
    "\n",
    "\n",
    "#Hard-coding labels\n",
    "y_test_web=np.zeros(6, dtype=int)\n",
    "\n",
    "y_test_web[0]=1     # Speed limit (30 km/h)\n",
    "y_test_web[1]=25    # Road work\n",
    "y_test_web[2]=0     # Speed limit (20 km/h)\n",
    "y_test_web[3]=17    # No entry\n",
    "y_test_web[4]=14    # Stop\n",
    "y_test_web[5]=28    # Children crossing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image, and Analyze Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process, normalizing image data\n",
    "X_test_web = (X_test_web-128.0)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the images\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    # one hot encoding of labels\n",
    "    ohe=sess.run(one_hot_y,feed_dict={y: y_test_web})\n",
    "   \n",
    "    # Softmax for each shape\n",
    "    sm = sess.run(tf.nn.softmax(logits),feed_dict={x: X_test_web, y: y_test_web} )\n",
    "    \n",
    "    # Top 5 probablities\n",
    "    top5 = sess.run(tf.nn.top_k(sess.run(tf.nn.softmax(logits),feed_dict={x: X_test_web, y: y_test_web} ), k=5))\n",
    "    print(\"Top 5 = \", top5)\n",
    "    \n",
    "    # Evaluate correct prediction \n",
    "    pred = sess.run(correct_prediction, feed_dict={x: X_test_web, y: y_test_web})\n",
    "    print(\"Prediction = \",pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix 1 - Data Set Augmentation Code\n",
    "\n",
    "As explained, the data set was augmented by introducing new images, each one generated starting by a random existing one and then:\n",
    "\n",
    "* Applying a rando rotation in the range \\[-20,20\\] degrees\n",
    "* A random increment in lighting up to the 80%\n",
    "\n",
    "A check is performed before the lighting change to be sure that it happens only on \"dark\" images.\n",
    "\n",
    "The new images and then appended at the bottom of the existing vectors.\n",
    "New images are generated for underrepresented classes, and the number of samples is defined so to have every class represented as the one that currently has the highest number of items ('Speed Limit (50 km/h)', with 2010 occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectors to original dataset\n",
    "X_train_aug=X_train\n",
    "y_train_aug=y_train\n",
    "\n",
    "# Note: the following variables are also defined in the previous code cells. Depending if/when this is executed, \n",
    "# they could be commented out\n",
    "z = np.array(Counter(y_train).most_common())\n",
    "lbls=z[:,0] # Array of lables\n",
    "occs=z[:,1] # Occurrence of every label, ordered from the most common\n",
    "\n",
    "# Iterate on the labels\n",
    "for i in range(1,len(lbls)-1):\n",
    "    print('Step :', i)\n",
    "    \n",
    "    # How many images are needed. occs[0] is the most common\n",
    "    delta_img =occs[0]-occs[i]\n",
    "    print('images needed = ',delta_img)\n",
    "    \n",
    "    # Identify the indeces of the images in X_train that are identified by the current label\n",
    "    searchval = lbls[i]\n",
    "    ii = np.where(y_train == searchval)[0]\n",
    "    \n",
    "    # Iterate on the num. of images needed\n",
    "    for j in range(1, delta_img):\n",
    "        \n",
    "        # pick a random imge associated with the current label\n",
    "        rand_ind=random.randint(0, len(ii)-1)         \n",
    "        img = X_train[rand_ind]\n",
    "        \n",
    "        # apply a random rotation\n",
    "        rotation = random.randint(-20, 20)\n",
    "        M = cv2.getRotationMatrix2D((16,16),rotation,1)\n",
    "        dst = cv2.warpAffine(img,M,(32,32))\n",
    "        \n",
    "        # appy a random lighting increment\n",
    "        a = np.double(dst)\n",
    "        avg = np.average(a)\n",
    "        b=a\n",
    "        \n",
    "        # Check on average value\n",
    "        if (avg<50.0):\n",
    "            light_inc=(random.random()*0.8)+1\n",
    "            b = a*light_inc\n",
    "            \n",
    "        # Append image and label\n",
    "        X_train_aug=np.append(X_train_aug,[np.uint8(b)],axis=0)\n",
    "        y_train_aug=np.append(y_train_aug,searchval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary and dump it in a pickle file\n",
    "\n",
    "aug_train = {\"augmented_pictures\":X_train_aug,\"augmented_labels\":y_train_aug}\n",
    "pickle.dump( aug_train, open( \"augmented_train.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix 2: Visualize the Neural Network's State with Test Images\n",
    "\n",
    "In this section we will show the output of some of the layers defined in the network, to gain insight on its work. We have named the layers in the architecture, so extracting them will be relatively straightforward.\n",
    "\n",
    "The layers will be fed with the first of the image loaded from the web.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pre-defined function\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first layer\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    lay1=sess.graph.get_tensor_by_name(\"Layer1_0:0\")\n",
    "    outputFeatureMap(X_test_web[0].reshape(1, 32,32,3),lay1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
